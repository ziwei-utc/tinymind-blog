---
title: Week 1 - Reading stuff
date: 2026-01-08T14:12:34.414Z
---



# personal 

- 2026 年，如果只选一个习惯，只要做到每天稳定执行，就会最大程度上改变我的人生！这个习惯是什么？

ChatGPT:

如果 2026 年只能选一个习惯，而且你要的是那种
只要每天稳定执行，就会在一年、三年、十年后明显拉开人生差距的东西，
那我给你的答案很直白，也可能有点不讨喜：

每天固定一段时间，做“无输入、无干扰的主动思考与输出”。

不是阅读。
不是刷信息。
不是学习新东西。
而是——把你脑子里已经有的东西，逼出来。

⸻

为什么不是运动、早睡、冥想、学习英语？

这些都重要，但它们有一个共同问题：
它们主要在“维护系统”，而不是“改变轨迹”。

而你现在这个阶段，其实已经不是一个“系统太差”的人了。

你缺的不是更多健康知识、更多工具、更多方法。
你缺的是一个每天都会逼你做判断、形成观点、制造差异的机制。

⸻

这个习惯具体长什么样？

每天 30–60 分钟，固定时间，雷打不动：
•不看资料
•不打开社交媒体
•不消费任何新信息
•只有三个动作之一（任选其一）

1️⃣ 写下你对一件事的真实判断
比如：
“我现在这个项目，最不体面的真相是什么？”
“我今天其实在逃避什么？”
“如果这件事三年后失败，原因最可能是哪三个？”

2️⃣ 把一个模糊想法压成清晰表达
不是长文。
是一段可以被别人理解、反驳、传播的观点。

3️⃣ 复盘一个具体决策或行为
只问三个问题：
我当时真正想要的是什么？
我基于什么假设行动？
结果验证了哪个假设是错的？

⸻

这个习惯为什么“狠”？

因为它会带来三个你躲不开的后果：

第一，你会越来越难自欺。
每天面对自己真实想法的人，很难长期活在幻觉里。

第二，你会自然筛掉 80% 没价值的输入。
因为你发现，真正稀缺的不是信息，而是判断。

第三，它会自动放大你所有其他习惯的回报率。
运动、学习、社交、投资、创作
一旦经过“主动思考”，都会变成杠杆。

⸻

换句话说

很多人一年改变不大，不是因为不努力，
而是 每天都在“被动反应世界”，从不主动构建自己的解释系统。

而你如果每天做这一件事：

世界不会变慢
但你会越来越快地看懂它

⸻

最后一句狠话（但我觉得你扛得住）

能改变人生的习惯，往往不“让人感觉良好”。
它们更像一面每天照一次的镜子。

2026 年，如果你愿意每天站在镜子前 30 分钟，
不逃、不装、不糊弄。

你的人生方向，大概率会自己开始转弯。

Gemini:

在 2026 年这个信息过载、AI 全面介入生活的时代，如果只能选择一个习惯，并且要对人生底层逻辑产生“杠杆效应”，那这个习惯一定是：
深度复盘（Daily Reflection & Review）
之所以不是“早起”、“健身”或“阅读”，是因为这些习惯只是在执行单一维度的优化，而复盘是对你整个“人生系统”的审计与升级。
为什么“复盘”在 2026 年最重要？
 * 对抗“算法投喂”： 现在的世界由算法驱动，如果你不主动思考，你的注意力会被碎片信息彻底撕碎。复盘强迫你从执行者切换为观测者。
 * 纠偏能力比速度更重要： 勤奋如果不被检视，极有可能是低水平的重复。每天花 10 分钟复盘，能确保你始终走在正确的航道上。
 * 情绪的“断舍离”： 现代人的压力往往来自未处理的情绪堆积。通过复盘将压力具象化，可以极大地缓解焦虑。
如何操作？（三步极简法）
不要试图写长篇日记，那很难坚持。你只需要每天睡前在手机或笔记本上回答三个问题：
 * 今天最让我有成就感/快乐的一件事是什么？（强化正向反馈，提升幸福感）
 * 今天哪件事做得不够好，如果重来一次我会怎么做？（识别错误模式，迭代大脑算法）
 * 明天最重要的“那一件事”是什么？（锁定核心目标，避免盲目忙碌）
坚持这个习惯会带来的改变

| 维度 | 短期变化（1个月） | 长期变化（1年以上） |
|---|---|---|
| 认知 | 发现自己时间的“黑洞”在哪里。 | 形成敏锐的直觉，决策质量显著提升。 |
| 情绪 | 焦虑感降低，睡得更踏实。 | 变得内核稳固，不容易被外界环境左右。 |
| 事业 | 工作效率提升，不再被琐事拖累。 | 产生复利效应，在擅长的领域积累出护城河。 |
> 核心逻辑： > 只要你每天都在比昨天的自己聪明一点点（哪怕只有 0.1\%），根据复利公式 (1 + 0.001)^{365} \approx 1.44，一年后你将比现在强大近 1.5 倍。
> 
你想现在就开始尝试吗？我可以帮你设计一个专属的 2026 复盘模版。

# About AI - Terrance Tao

大模型本身数学并不难，难的是人类预测不了它！菲尔兹奖得主陶哲轩：AI正在把数学从"手工艺"推向"规模化生产"，数学家未来将成为架构师




Original





听雨







51CTO技术栈




2026年1月4日 02:40



4002人












在小说阅读器中沉浸阅读
















编辑｜听雨“训练和运行大模型的数学本身并不复杂，一个本科数学专业的学生就具备所有知识：矩阵乘法，加一点微积分。真正缺乏理论的是：我们无法预测模型的表现。”最近，著名数学家、菲尔兹获得者陶哲轩两次接受采访，公开表示大语言模型和现代AI的数学门槛没那么高，却有个“致命短板”：“真正的难点不在于让这些模型如何运行，我们已经知道怎么构建、训练和操作大语言模型了。难点在于理论层面我们缺少可靠的方法来评估或预测它们的性能。”关于陶哲轩，相信大家并不陌生。2023 年底，陶哲轩领导团队在三周内完成多项式 Freiman-Ruzsa 猜想（Polynomial Freiman-Ruzsa Conjecture，PFR）的 Lean 形式化验证；2024 年发起“等式理论计划”（Equational Theories Project），他正在身体力行地推动一场数学研究范式的变革。在这两次公开访谈中，陶哲轩坦诚地分享了自己对形式化工具、AI 技术在数学中的运用以及对数学研究未来影响的看法。
在与美国宇宙学家 Brian Keating的对话中，陶哲轩透露，AI已经开始促成一些新的数学发现。比如在结理论中，人们用一种并不复杂的神经网络发现了此前没人预料到的结不变量之间的相关性。神经网络提供了一种不同于传统实验或理论的新研究范式：先发现数学中隐藏的相关性，再由人类进行证明。另外，陶哲轩指出AI 已经在文献回顾领域显现价值。对于某个数学问题，文献中可能已经有十几种处理方法，研究者可能只记得其中几种，而模型可以用来“提醒”你那些遗漏的方法。
陶哲轩认为AI目前本质上还是一个不可靠的工具，但不可靠的工具也可以很有价值。AI的真正优势在于规模化，可以在数学研究中辅助解决数以百万计的中等难度问题，但关键在于，只在你能验证的范围内使用 AI。此外，陶哲轩指出，AI也会影响未来的数学教育。现在AI已经可以完成大量数学本科阶段的作业，因此必须重塑教学方式，未来需要培养的核心能力是验证信息的能力。而在另一期访谈——与前 OpenAI 研究科学家、Morph Labs 创始人 Jesse Han，以及斯坦福大学助理教授 Jared Duker Lichtman的对话中，陶哲轩直言，AI在数学研究者替代了大量重复性劳动——如查阅文献、调整他人论文中的参数以及繁琐的计算，加速了数学研究的进展。他举了个例子——液态张量实验，如果放在20世纪动辄需要几十年才能完成，现在仅仅花了18个月。陶哲轩判断，AI会让数学走向”规模化生产”的模式，未来的数学家可能扮演“架构师”或项目经理的角色，领导大型协作项目。这种模块化的研究方式会允许”公民数学家“（非专业领域专家但具备某些技能的人）参与到前沿研究中，降低数学研究的门槛。由于AI能够替代数学家完成很多繁琐重复的劳动，当AI工具真正成熟后，陶哲轩认为“我们做数学的方式可能会完全改变”。AI能帮助研究者发掘原本“错失的研究机会”，从而改变未来数学研究的路径。小编精心整理了两期访谈中与AI相关的部分内容，希望对各位有帮助，enjoy！
AI看起来在做“推理”但实际上并没有扎根于理解Brian Keating：
AI 是否已经真正促成了一些不会出现的数学发现或新证明？陶哲轩：
正在缓慢地开始。单独来看，目前 AI 的一个巨大弱点在于：它们可以生成看起来像人类数学家在“推理”的输出，但这些推理并没有真正扎根于理解。它是“修辞性的”，而非扎实的推理。它们经常会犯错。这很像一个学生在黑板前紧张地解题：有时可能对，有时可能错。但如果这个学生基础不牢，一旦偏离正轨，就会偏离得非常彻底。这正是当前大语言模型的一个根本问题。不过，如果你把它们作为更严谨、可验证推理系统中的一个组件来使用，情况就不同了。比如，让大语言模型提出建议，而由人类理解、筛选并验证这些输出。在这种模式下，已经有人取得了一些成功：你向模型描述一个数学问题，它会给出若干思路，其中一些显然不可行，会被专家直接否定；一些是“我早就想过的”；但偶尔会出现一两条你本该想到、但却没想到的，真正有价值的提示。目前 AI 已经开始显现价值的一个领域是文献回顾。某一类问题，文献中可能已经有十几种处理方法，而研究者可能只记得其中六种，其余六种一时想不起来。模型可以用来“提醒”你那些遗漏的方法。当然，它也可能凭空捏造三种根本不存在的方法。所以你绝对不能信任它，必须进行监督与验证。未来的希望在于：存在另一类技术——形式化验证软件，可以自动验证某些类型的证明。如果我们强制大语言模型只输出可被验证语言中的内容，就可以在很大程度上过滤掉幻觉。
神经网络可以发现数学中隐藏的相关性Brian Keating：
那它是否已经能够“复现”某些非常激进的证明或定理？比如你的工作，Navier–Stokes 方程之类？它能否真正做出一个自然智能（比如你）会做的事情？陶哲轩：
在某种意义上，它“可以”，但往往是因为训练数据污染。如果一个结果已经出现在教材或软件中，那么它很可能已经进入训练数据。于是 AI 所做的，只是像学生背诵教材一样进行记忆性复现。AI 基本上“读过世界上所有教材”。因此很难区分它是在真正“思考”，还是仅仅在复述训练内容。如果你要求 AI 解释它的“思维链”，往往会发现输出完全是胡说八道，很明显它并不知道自己在做什么。Brian Keating：
是的。我和学生 Evan Watson 也试过。我们给它提供了过去 3000 年水星轨道的数据（JPL 可以算出来），然后问：你能否先“发现”水星近日点进动异常，再预测它？
结果完全失败。我们不得不先把一切离散化、欧几里得化，而这反而破坏了问题本身。我开玩笑提出过一个“Keating 测试”，类似图灵测试：当 AI 能提出此前未知、且能被人类验证的新预测时，我们就知道它是真的智能了。陶哲轩：
这是一个非常有前景的应用方向。神经网络本质上是用来发现模式、相关性的。确实已经有一些数学例子：在结理论中，人们用一种并不复杂的神经网络（不是大语言模型）发现了此前没人预料到的结不变量之间的相关性。注：结理论（Knot Theory）是数学中一个研究“结”这种几何—拓扑对象的分支，隶属于拓扑学（Topology），同时与几何、代数、物理（尤其是量子物理）有深度交叉。具体来说：研究者向神经网络输入了约一百万个结的数据。结有许多不变量，其中一个叫“签名（signature）”，另一些是“超曲几何不变量”。神经网络发现：仅根据这些超曲几何不变量，就可以以约 90% 的准确率预测结的签名值。起初这是一个完全的黑箱：输入 20 个数，输出“签名是 +3”。但随后研究者开始“探测”这个黑箱：改变某一个输入，观察输出如何变化。最终发现，20 个输入中，只有 3 个真正重要，其余 17 个影响很小。通过这种分析，他们获得了对结构的理解，并最终提出了一个可以被严格证明的数学命题。所以，神经网络可以作为一种启发式工具：先发现现象，再由人类抽象、证明。在你的天文学例子中，神经网络也许无法直接告诉你新的物理定律，但它可以预测未来 1000 年水星轨道的行为。然后你可以做“反事实实验”：改变质量、周期，观察输出变化，从而实验性地推断自然规律。这提供了一种不同于传统实验或理论的新认识现实的范式。
训练和运行AI只需本科数学知识
困难在于预测模型表现Brian Keating：
很多 AI 悲观论者担心 AI 会失控，但它似乎只是“平均化人类知识”，因此错误也是受限的。但它又确实有点“魔法”。
从数学角度看，支撑 AI 的不就是大规模矩阵乘法吗？真的那么复杂吗？陶哲轩：
训练和运行现代 AI 的数学本身并不复杂。一个本科数学专业的学生就具备所有先修知识：矩阵乘法，加一点微积分。真正缺乏理论的是：我们无法预测模型的表现。我们知道如何构建、训练、运行模型，但不知道它在哪些任务上会表现得好，哪些不行，甚至连启发式规则都没有，只能做经验实验。原因之一是：我们缺乏对“部分结构化数据”的数学理论。完全随机的数据我们懂；高度规则的数据我们也懂；但像自然语言这种既不完全随机，又不完全可预测的数据，我们没有合适的数学工具。这和物理学中的“介观尺度”问题很像：连续介质力学我们懂，原子物理我们也懂，但像细胞这样的涌现结构，我们并没有良好的理论。
AI已经可以大量完成数学本科的作业Brian Keating：
你既是数学家，也是教育者。你如何看待未来的教育？陶哲轩：
教育必须发生巨大变化。世界变得更加复杂、不稳定、不可预测。过去，人类几乎垄断了认知任务；现在不是了。
AI 不会很快取代研究级数学家，但本科阶段的作业已经大量可以被 AI 完成。因此，我们必须重塑教学方式。未来一个核心能力是验证信息的能力。过去，权威信息源很少；现在信息极多，质量参差不齐，而且高质量呈现已经不再意味着高质量内容。你可以看到外观完美、逻辑却根本错误的教材、视频或 AI 输出。因此，我们需要培养批判性思维。我已经看到教师尝试这样教学：“这是我原本会布置的题目，这是 ChatGPT 的答案——它是错的。请你指出错误并修正。”知识不应再被视为被动接受的权威，而是必须不断质疑和挣扎的对象。
AI可以处理数百万中等难度问题规模是最大优势Brian Keating：
未来 AI 能否“自我监督”？能否让 AI 去审查 AI？陶哲轩：
也许可以提高可靠性，但以当前架构来看，AI 本质上是不可靠的工具。但不可靠的工具也可以非常有用。随机数生成器极其不可靠，却是密码学的基石。关键是，只在你能验证的范围内使用 AI。我认为 AI 最重要的价值，并不在于解决最顶级的问题，而在于处理数以百万计的中等难度问题。哪怕它只成功解决 10%，那也是 10 万个问题。
规模，才是它真正的优势。你无法用这种方式扩展研究生，至少在法律和伦理上不行，但 AI 可以。
从几十年到18个月AI正在加速数学研究陶哲轩：说实话，在我整个学术生涯中，我一直觉得我们做数学的方式少了点什么。我们在研究一个数学问题时，总想找到那个能打开问题大门的精妙想法。但在那之前，有大量枯燥的苦力活。比如文献综述，比如你在别人论文里看到一个技巧想用到自己的问题上，但所有的输入条件都有点不一样，你就得手动调整所有的论证。还有那些计算 —— 它们确实有用，能帮你建立直觉，但很多时候就是硬磨，不停地算啊算。我以前也试过写一些小程序来加速某些计算，但那时候技术还不成熟。大概两年前，就在 IPAM（纯粹与应用数学研究所）这里，我们办了一个机器辅助证明的会议，我是组织者之一。在那次会议上，我们接触到了各种各样的尝试 ——SAT 求解器、计算机辅助软件包、大语言模型。ChatGPT 刚问世，还有 Lean。那是一个令人兴奋的世界，你突然发现很多事情变得可能了，而且正在发生。比如 Peter Scholze 刚完成了一个长达 18 个月的项目，把他的一个重要定理形式化了。Jared Duker Lichtman：液态张量实验。陶哲轩： 对，液态张量实验。这是个大工程，一个定理花了 18 个月。但这已经被认为是巨大的突破了，因为 20 世纪的那些形式化项目，动辄要花几十年才能完成。所以这本身就是一个巨大的提速，部分原因是我们已经学会了如何使用软件工程的那些工具，比如 GitHub，以及更智能地组织这些项目。从那以后，我对 AI 和形式化都产生了浓厚的兴趣。Jared Duker Lichtman： 就是因为那次会议。陶哲轩： 对，没错。我开始相信这就是数学的未来，也开始接受一些采访谈这个话题。但到了某个时候，你不能光说不练，得真正动手。所以我就去学了 Lean，花了大概一个月，但其实挺好玩的。这让我想起了写本科分析教材的经历 —— 真的是从基础开始，把每一步都做到完全严格。感觉就像在玩电子游戏。我记得 Kevin Buzzard 说过，Lean 是世界上最好玩的电子游戏，大概是这个意思。
AI会让数学走向规模化生产数学家也可以是架构师Jesse Han：
我想补充一点。你在几年前发表于《美国数学会通告》（Notices of the AMS）的一篇文章中说过一些非常有意思的话，谈到你如何看待数学家角色的演变。我也很好奇，你在组织这些形式化项目的过程中，是如何感受到自己角色变化的？以及你在运行 Polymath（多数学家） 项目中积累的经验，是如何与这些想法交汇的？陶哲轩：
是的。我一直有一种感觉：我想做的数学远远多于我一个人能够完成的量。因此，我一直觉得合作极其高效。我从合作者身上学到了很多，也从互联网上的随机互动中学到了很多。比如，我当年开始写博客，其实是因为我曾在自己的网站上随意贴了一个数学问题，本来并不指望有人回答。但当时已经有足够多的人在看我的网页，结果三天之内，就有人给了我一个完整的文献出处，告诉我这个问题最早来自哪里。现在，这样的问题可能一句 ChatGPT 就能解决，但在当时，对我来说是革命性的体验。后来 Tim Gowers 提出了 Polymath 项目，试图对数学研究进行“众包”。我非常享受这种方式，它和我的直觉高度契合：参与人数越多，产生“偶然连接”的概率就越高，而这些连接往往是任何一个再专家的人单独工作都发现不了的。但 Polymath 项目始终存在一个瓶颈：当有十几、二十个人同时贡献内容时，总得有人去检查所有结果，确保逻辑一致、内容连贯，并进行总结。这个人通常是我、Tim Gowers，或者其他几位核心成员。这非常、非常耗费精力。Jared Duker Lichtman：
就像一个星形图结构，有一个中心节点，对吗？陶哲轩：
正是如此。所以，尽管这种范式非常有前景，但它并不能真正扩展到更大规模。不过，它确实让我们能够开展一些极其宽广的项目：很多人从完全不同的数学分支带来了我们事先完全不知道、却高度相关的连接。问题在于，我们当时缺乏验证与组织的基础设施。我们是在博客和 Wiki 上运行这些项目的，而不是像今天这样使用 GitHub。如果现在重来一遍，技术条件会好得多。这些新工具，形式化与 AI，真正改变的一点是：它们可以实现不同技能层级之间的无缝协作。比如在一个形式化项目中，并不是每个人都需要懂 Lean，也不是每个人都需要懂数学，或者懂 GitHub；你只需要一组技能彼此重叠的人，各自负责一块。这也让数学项目中真正意义上的“分工”成为可能。传统数学合作中，即便有两三个合作者，每个人也必须什么都懂：数学本身、LaTeX 写作、细节检查，每个环节都要参与。这是一种“人人全能”的模式。但在真正的分工体系里，就像工业化生产会有项目管理者、质量控制人员等。软件工程已经完成了这种转变：早期也是一个人写所有代码，但那根本无法扩展；一旦你要做企业级软件，就必须高度专业化。我认为数学也会走向某种“规模化生产”的模式。当然，传统的、手工打造的数学仍然非常重要、也非常有价值，但这两种方式将是互补的。Jesse Han：
那是否意味着，你认为未来大多数职业数学家的角色，会演变成某种“系统架构师”？陶哲轩：
我认为“数学家”的定义会被显著拓宽。会有一类人擅长运行大型项目，他们可能是项目管理者；他们懂足够多的数学和 Lean，可以在高层理解整体结构，但不一定能修复每一个具体的技术细节。也会有一类人非常擅长形式化，或者非常擅长使用 AI 工具，但并非某个领域的专家。人们可以更自由地加入或退出项目。当然，小规模、每个人都参与所有环节的传统合作方式仍然非常重要。关键在于：我们拥有选择。现在的问题是，许多真正喜欢数学的人被挡在研究之外，因为门槛太高了。你要参与前沿研究，必须掌握博士级数学、熟练 LaTeX、几乎不允许犯任何错误。这对很多“数学相邻人群”来说太令人望而生畏了。而即便有人勉强进入，也常常因为技能结构不完整而被忽视。Jared Duker Lichtman：
但社会对“公民数学家”其实是有巨大需求的，就像公民科学一样。陶哲轩：
确实如此。我参与的一个问题网站已经形成了一个由几十位、数学背景差异巨大的人组成的社区。我们学会了把问题模块化：也许你解不了这个问题，但你可以查文献、联系整数序列、评论别人的证明、做数值实验。对研究级数学的潜在需求是非常强烈的，而这些工具有望释放这种潜力。
AI应该帮数学家“干苦力活”Jesse Han：
你刚才提到形式化、协作和自动化。我觉得这是一个很好的时机，谈谈你现在最兴奋推动的项目：解析数论中界（bounds）的形式化。能否用一种外行也能理解的方式，解释为什么这个问题重要？以及它如何反映我们前面讨论的所有问题？陶哲轩：
我通常把自动化看作是对人类思维的补充。最直观的用法是：让计算机去解决人类最想解决的难题，比如黎曼猜想。但短期内，计算机更擅长做的是人类不喜欢做的事——大量繁琐、重复、参数极多的计算。在解析数论中，恰恰存在这样一大片工作：极度枯燥，但目前仍主要由人类完成。Jared Duker Lichtman：
对我来说，至少 70% 的时间都耗在这种“苦力活”上。陶哲轩：
没错。我们有很多非常强大的工具，可以把关于指数和、ζ 函数等的一个陈述转换为另一个。但这些工具都有输入和输出条件，必须被小心地串联起来。不同论文的记号不一致，假设条件也略有不同，你往往要重新拆解整个证明，重新实现一遍。这导致大量重复劳动和人为错误。为了减轻负担，我们常用一个“作弊技巧”：不去管常数。把 27、38 全部写成一个 C。这样能减少计算，也能避免算错常数。代价是：结果不再是显式的。你可能证明了“足够大的奇数都可以表示为三个素数之和”，但“足够大”到底是多少？不知道，因为你没算。显式解析数论因此成为一个很小的子领域，因为工作极其繁琐，论文也非常难读。这并非作者的问题，而是问题本身的性质决定的。但这正是自动化的理想目标。如果我们能把这些工具形式化，自动匹配参数、组合界限，甚至用 AI 去寻找最优组合路径，那么整个领域都会发生变化。理想状态下，如果有人改进了 ζ 函数的某个界，我们只需把它“插入”一个形式化系统，就像改 Excel 里的一个单元格，其它所有结果都会自动更新。我们可以拥有一个“实时更新”的解析数论前沿状态，而不是每十年重写一篇综述论文。Jesse Han：
所以这本质上是一个软件工程问题？陶哲轩：
是的。就像早期编程中的汇编语言一样：枯燥、不像文学。但一旦能在更高层抽象上推理，一切就不同了。Lean 提供了一种几乎无 bug 的互操作方式，这是我们目前完全缺乏的东西。
AI能否整体改写数学的研究路径？Jared Duker Lichtman：
你是否可以尝试推测一下，在数论或者其他数学分支中，大概有多少比例的工作，其实是由这些相对枯燥、繁重的“体力活”构成的？如果这种工作负担的结构发生变化，是否会导致一种完全不同的研究工作流？Jesse Han：
从历史上看，其实一直存在一些并非依赖形式化验证、也不是严格计算意义上的“技术进步”，但它们确实作为更好的数学工具出现，让数学家得以摆脱原先的一些繁琐劳动，从而思考新的问题。我很好奇，在解析数论的发展过程中，有哪些例子是特别关键的？随着人们对这个领域的理解方式发生变化，哪些技术真正改变了研究方式？以及，像 Lean 这样的形式化工具和自动形式化技术，是否也可以被看作是这类技术演进的一个实例？陶哲轩：
数论其实是最早采用“实验数学”的领域之一。比如数论中的瑰宝——素数定理，最初就是高斯通过非常痛苦地手算前十万甚至一百万个素数，从中观察规律后提出猜想的。Jared Duker Lichtman：
而且数据量其实非常小。陶哲轩：
是的，高斯展现出了一种非凡的能力，能够从非常小的数据集中进行概括推断——这也是把工具命名为 “Gauss” 的原因之一。后来，随着计算能力的提升，我们可以进行更广泛的探索。比如 Birch–Swinnerton-Dyer 猜想，也是通过数值实验发现的；再到近些年，甚至开始出现借助机器学习进行枚举和探索的例子。Jared Duker Lichtman：
图灵当年也在计算 ζ 函数的零点。陶哲轩：
是的，黎曼猜想在很大程度上也是通过大量数值证据获得支持的。历史上确实存在一个传统：利用计算机，不只是辅助“计算”，而是开启一种新的做数学的方式——不再仅仅依赖纯粹的思维推演，而是数据驱动、计算机辅助。当然，形式化并不完全等同于数据驱动数学，但它显然是一种计算机辅助的方式。Jared Duker Lichtman：
对于一个平均意义上的数学家，比如做数论或者其他领域的研究者，他们日常工作中有多大比例，是被这种“繁重劳动”所瓶颈住的？陶哲轩：
这个比例很难精确量化，但我认为它的影响更多是间接的。正因为这些繁重工作存在，我们往往会有意识地改变研究方式，以减少这类负担。比如一旦发现某条计算路径变得非常混乱、复杂，我们往往会主动绕开它，改走别的方向。因此，如果你只从论文结果本身来看，似乎“繁重劳动”所占比例并不高——但那是因为我们在研究过程中，几乎是下意识地避开了这些“坑”。当这些工具真正成熟之后，我认为我们做数学的方式会发生变化。到那时，如果遇到一个需要大量、繁琐计算的障碍，我们就会直接动用所有技术手段，强行推进，比如说：“好，从这里到那里，用 Gauss 或者其他工具直接解决。”然后继续往前。这意味着我们可以直接穿越那些过去几乎本能回避的障碍。所以，表面上看，繁重劳动在成果中的比例似乎不高；但如果从“错失的研究机会”这个角度来看，它的比例其实非常巨大。Jesse Han：
你之前提到，一个很重要的瓶颈在于寻找合适的合作者，以及在彼此之间建立那种对问题状态的共享理解。尤其是在解析数论中，研究往往涉及大量具体界的传播和组合。你觉得在这类研究中，有多少时间是被“人与人之间沟通”和“分布式的人类计算”所限制的？如果你设想的那种未来愿景能够实现，这个领域的研究效率大概可以提升多少倍？陶哲轩：
这里首先是一个“信任”问题。如果在这些复杂计算中，某一步出了错，整个结论就都不成立。因此，你必须知道哪些作者是可靠的，哪些不是——但这种信息是隐性的，我们不会公开发布所谓的“黑名单”。目前，你需要非常熟悉这个学术共同体，知道该向谁求证、该信谁。如果某个结果尚未正式发表，但你知道可以去问某位专家，对方可能会告诉你：“是的，这个是真的，只需要稍作修改。”这就导致一个瓶颈：你必须身处这个“关系网络”之中，才能顺利开展研究。如果我们能够通过 Lean 这样的形式化系统提供一种可靠的“信任保证”，那么这个领域就可以对更多人开放，你也可以安全地使用那些你从未见过的研究者的结果——因为所有证明都已经被形式化系统验证过了。这将极大地解放研究效率。Jared Duker Lichtman：
我理解你说的“信任积累”过程。研究者在一个领域里长期工作，慢慢建立声誉。一个让我对形式化和数学基础产生兴趣的故事是 Voevodsky 的经历：他在早期证明了许多极其重要的结果，积累了极高的信任度。但在 90 年代后期，他发表了一篇论文，十年后才意识到其中存在一个致命错误。他自己也反思说，人们之所以接受这篇工作，很大程度上是因为他过往的声誉，而不是因为证明本身得到了充分验证。陶哲轩：
是的。确实存在一个极限：在当前这种依赖“信任网络”的体系下，数学能被推进的深度是有限的。在分析领域，这个问题相对小一些，因为我们通常更贴近第一性原理、从基础一步步构建。但在整体上，这确实是数学发展的一个限制因素。Jared Duker Lichtman：
作为一个延伸问题，随着我们开始形式化一些经典文献，比如上世纪六七十年代的一些重要论文，你觉得目前文献中可能还隐藏着多少尚未被发现的错误？以及，其中有多少只是可以轻松修补的小问题，而整个数学体系是否对这类错误具有足够的鲁棒性？陶哲轩：
我不知道。我也很期待真正看到这个“错误率”是多少。也许我们会得到一个令人欣慰的答案，也可能会感到不安。六个月后再来问我吧。参考链接：https://www.youtube.com/watch?v=ukpCHo5v-Gchttps://www.youtube.com/watch?v=4ykbHwZQ8iU